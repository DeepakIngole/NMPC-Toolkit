---
subtitle: "Nonlinear Model Predictive Control for"
title: "Autonomous Race Cars"
author: "Behzad Samadi"
date: "Research Group, Maplesoft, Waterloo"
output:
  beamer_presentation:
    fonttheme: structurebold
    fig_caption: false
    includes:
      after_body: src/beamersuffix.tex
      before_body: src/beamerprefix.tex
      in_header: src/beamerheader.tex
    keep_tex: yes
    template: src/beamertemplate.tex
bibliography: src/bibliography.bib
---

## Autonomous Race Cars Are Here

- Roborace will be a motorsport championship similar to the FIA Formula E Championship but with autonomously-driven electric race cars.

\begin{figure}[!htb]
\centering
\href{http://danielsimon.com/roborace-robocar/}{\includegraphics[width=0.79\textwidth]{img/Roborace_DanielSimon_Robocar_002.jpg}}
\url{http://danielsimon.com/roborace-robocar/}
\end{figure}



## Model Predictive Driver
- A race driver needs to look forward! (**prediction**)
- Minimize a cost function at each time instant depending on the current situation (**closed loop optimal control**)
- Optimization constraints:
    - Vehicle's dynamic behavior
    - Limited power
    - No skidding
    - Following the road
    - Avoiding collision

![](img/MPCroad.pdf)

## Model Predictive Control
- MPC is the optimal controller in the loop:
    1. Measure/estimate the current state $x_n$.
    1. Solve the optimal control problem to compute $u_k$ for $k=n,\ldots,n+N-1$.
    2. Return $u_n$ as the value of the control input.
    3. Update $n$.
    4. Goto step 1.
- MPC is implemented in real time.

## NMPC: Problem and Solution

![NMPC](img/NMPC_bigpic.pdf)

## Nonlinear Model
- Consider the following nonlinear system:
\begin{align*}
\dot x(t)=&f(x(t),u(t))\\
x(t_0)=&x_\circ
\end{align*}
where:
    - $x(t)$ is the state vector
    - $u(t)$ is the input vector

## Optimal Control Problem
\begin{align*}
\underset{u}{\text{minimize}}\ & J(x_0,t_0)=\phi(x(t_f))+\int_{t_0}^{t_f}L(x(\tau),u(\tau))d\tau \\
\text{subject to} &\ \dot x(t)=f(x(t),u(t))\\
                  &\ x(t_0)=x_\circ\\
                  &\ g_i(x(t),u(t)) = 0, \text{ for }\ i=1,\ldots,n_g\\
                  &\ h_i(x(t),u(t)) \leq 0, \text{ for }\ i=1,\ldots,n_h
\end{align*}

## Discretization
- Discretize the problem into $N$ steps from $t_0$ to $t_f$:
\begin{align*}
\underset{u,\alpha}{\text{minimize}} &\ \phi_d(x_N)+\sum_{k=0}^{N-1}\left(L(x_k,u_k) \right)\\
\text{subject to} &\ x_{k+1}=f_d(x_k,u_k)\\
                  &\ x_0=x_\circ\\
                  &\ g_i(x_k,u_k) = 0, \text{ for }\ i=1,\ldots,n_g\\
                  &\ h_i(x_k,u_k) \leq 0, \text{ for }\ i=1,\ldots,n_h\\
\end{align*}
where $\Delta\tau=\frac{t_f-t_0}{N}$ and:
\[\phi_d(x_N)=\frac{\phi(x(t_f),t_f)}{\Delta\tau}\]
\[f_d(x_k,u_k)=x_k+ f(x_k,u_k)\Delta\tau\]

## Interior Point - Barrier Method
- Using a particular *interior-point algorithm*, the *barrier method*, the inequality constraints are converted to equality constraints:
\begin{align*}
\underset{u,\alpha}{\text{minimize}} &\ \phi_d(x_N)+\sum_{k=0}^{N-1}\left(L(x_k,u_k)-r^\text{T}\alpha_{k} \right)\\
\text{subject to} &\ x_{k+1}=f_d(x_k,u_k)\\
                  &\ x_0=x_\circ\\
                  &\ g_i(x_k,u_k) = 0, \text{ for }\ i=1,\ldots,n_g\\
                  &\ h_i(x_k,u_k) + \alpha_{ik}^2 = 0, \text{ for }\ i=1,\ldots,n_h\\
\end{align*}
where $\alpha_k\in\mathbb{R}^{n_h}$ is a vector slack variable and the entries of $r\in\mathbb{R}^{n_h}$ are small positive numbers.


[@boyd2004convex]

\vspace{-2mm}
[@diehl2009efficient]

## Optimization Problem
\begin{align*}
\underset{u,\alpha}{\text{minimize}} &\ \phi_d(x_N)+\sum_{k=0}^{N-1}\left(L(x_k,u_k)-r^\text{T}\alpha_{k} \right)\\
\text{subject to} &\ x_{k+1}=f_d(x_k,u_k)\\
                  &\ x_0=x_\circ\\
                  &\ G(x_k,u_k,\alpha_k) = 0
\end{align*}
where:
\[ G(x_k,u_k,\alpha_k) = \left[\begin{array}{c}
                g_1(x_k,u_k)\\
                \vdots\\
                g_{n_g}(x_k,u_k)\\
                h_1(x_k,u_k) + \alpha_{1k}^2\\
                \vdots\\
                h_{n_h}(x_k,u_k) + \alpha_{n_hk}^2\\                
                \end{array}\right]\]

## Lagrange Multipliers
- Lagrange multipliers:
\vspace{-5mm}
\begin{align*}
\mathcal{L}(x,u,\alpha,\lambda,\nu)= &\ \phi_d(x_N,N)+ (x_\circ-x_0)^\text{T}\lambda_0\\
            &\ +\sum_{k=0}^{N-1}\left(L(x_k,u_k)-r^\text{T}\alpha_{k} \right.\\
            &\ +(f_d(x_k,u_k)-x_{k+1})^\text{T}\lambda_{k+1}\\
            &\ \left.+G(x_k,u_k,\alpha_k)^\text{T} \nu_{k} \right)
\end{align*}
- Optimality conditions:
\[\mathcal{L}_{x_k}=0, \mathcal{L}_{\lambda_k}=0\ \text{for}\ k=0,\ldots,N \]
\[\mathcal{L}_{\alpha_{k}}=0, \mathcal{L}_{u_k}=0, \mathcal{L}_{\nu_k}=0\ \text{for}\  k=0,\ldots,N-1\]

## Hamiltonian
- $\mathcal{L}(x,u,\alpha,\lambda,\nu)$ can be rewritten as:
\vspace{-5mm}
\begin{align*}
\mathcal{L}(x,u,\alpha,\lambda,\nu)= &\phi_d(x_N)+x_\circ^\text{T}\lambda_0-x_N^\text{T}\lambda_N\\
            &\ +\sum_{k=0}^{N-1}\left(\mathcal{H}(x_k,u_k,\alpha_k,\lambda_{k+1})-x_{k}^\text{T}\lambda_k\right)
\end{align*}
- Hamiltonian:
\begin{align*}
\mathcal{H}(x_k,u_k,\alpha_k,\lambda_{k+1},\nu_k)=&L(x_k,u_k)-r^\text{T}\alpha_{k}\\
            &\ +f_d(x_k,u_k)^\text{T}\lambda_{k+1}+G(x_k,u_k,\alpha_k)^\text{T} \nu_{k}
\end{align*}

## Pontryagin's Maximum Principle

                                      Optimality Conditions
--------------------------------     ---------------------------------------------------------------------------
$\mathcal{L}_{\lambda_{k+1}}=0$       $x_{k+1}^\star=f_d(x_k^\star,u_k^\star)$
$\mathcal{L}_{\lambda_0}=0$           $x_0^\star=x_\circ$
$\mathcal{L}_{x_k}=0$                 $\lambda_k^\star=\mathcal{H}_x(x_k^\star,u_k^\star,\alpha_k^\star,\lambda_{k+1}^\star,\nu_k^\star)$
$\mathcal{L}_{x_N}=0$                 $\lambda_N^\star=\frac{\partial}{\partial x_N}\phi_d(x_N^\star)$
$\mathcal{L}_{u_k}=0$                 $\mathcal{H}_u(x_k^\star,u_k^\star,\alpha_k^\star,\lambda_{k+1}^\star,\nu_k^\star)=0$
$\mathcal{L}_{\alpha_k}=0$            $\mathcal{H}_\alpha(x_k^\star,u_k^\star,\alpha_k^\star,\lambda_{k+1}^\star,\nu_k^\star)=0$
$\mathcal{L}_{\nu_k}=0$               $G(x_k^\star,u_k^\star,\alpha_k^\star) = 0$

for $k=0,\ldots,N-1$ where $\star$ denote the optimal solution

## cGMRES Method: Compute Optimality Conditions
- Step 1: Compute $x_k$ and $\lambda_k$ as functions of $u_k$, $\alpha_k$ and $\nu_k$, given the following equations:
\begin{align*}
x_{k+1}=&\ f_d(x_k,u_k)\\
x_0=&\ x_n\\
\lambda_k=&\ \mathcal{H}_x(x_k,u_k,\alpha_k,\lambda_{k+1},\nu_k)\\
\lambda_N=&\ \frac{\partial}{\partial x_N}\phi_d(x_N)
\end{align*}

[@ohtsuka2004continuation]

## cGMRES Method: Compute Optimality Conditions
- Step 2: For 
\[U=[u_0^\text{T},\ldots,u_{N-1}^\text{T},\alpha_0^\text{T},\ldots,\alpha_{N-1}^\text{T},\nu_0^\text{T},\ldots,\nu_{N-1}^\text{T}]^\text{T}\]
solve the equation $F(x_n, U)=0$, where:
\[
F(x_n, U)=\left[\begin{array}{c}
\mathcal{H}_u(x_0,u_0,\alpha_0,\lambda_1,\nu_0)\\
\mathcal{H}_\alpha(x_0,u_0,\alpha_0,\lambda_1,\nu_0)\\
G(x_0,u_0,\alpha_0)\\
\vdots\\
\mathcal{H}_u(x_{N-1},u_{N-1},\alpha_{N-1},\lambda_N,\nu_{N-1})\\
\mathcal{H}_\alpha(x_{N-1},u_{N-1},\alpha_{N-1},\lambda_N,\nu_{N-1})\\
G(x_{N-1},u_{N-1},\alpha_{N-1})\\
\end{array}\right]
\]

[@ohtsuka2004continuation]

## cGMRES Method: Solver
- *Continuation method*: Instead of solving $F(x, U)=0$, find $U$ such that:
\[\dot F(x, U)=A_sF(x, U)\]
where $A_s$ is a matrix with negative eigenvalues.
- Now, we have:
\[F_x\dot x+F_U\dot U=A_sF(x, U)\]

- *GMRES*: To compute $\dot U$ using the following equation, which is linear in $\dot U$, we use the generalized minimum residual (GMRES) algorithm.
\[F_U\dot U=A_sF(x, U)-F_xf(x,u)\]
- To compute $U$ at any given time, we need to have an initial value for $U$ and then use the above $\dot U$ to update it.

[@ohtsuka2004continuation]

## cGMRES Method: Solver

- *Numerical approximation*:
\[F_U\dot U\simeq \frac{F(x+hf(x,u),U+h\dot U)-F(x+hf(x,u),U)}{h}\]
\[F_xf(x,u)\simeq\frac{F(x+hf(x,u),U)-F(x,U)}{h}\]

[@ohtsuka2004continuation]

## Maple Implementation

- *Problem formulation*:
\[A(x,U,\dot U) = \frac{F(x,U+h\dot U)-F(x,U)}{h}\]
\[b(x,U) = A_sF(x, U)-\frac{F(x+hf(x,u),U)-F(x,U)}{h}\]
- $b(x,U)$ is only called once per each step at the beginning and $A(x,U,\dot U)$ is called several times by the GMRES solver.

## Maple Implementation
- Maple procedures are generated for $A$, $b$ and optimized.
- The GMRES solver is also implemented in Maple. 
- C code is then generated automatically.
- The C code is then used to simulate the closed loop system in Maplesim.

## Interior Point Methods

![cGMRES](img/cGMRES.pdf)

## Application: Autonomous Race Car

![Spacial vehicle model](img/SpatialVehicleModel.pdf){width=320px}

\vspace{-1cm}
\[\dot s=\frac{\rho_r}{\rho_r-y_r}(v_x\cos(\psi_e)-v_y\sin(\psi_e))\]


## Application: Autonomous Race Car

\begin{block}{Approximate Vehicle Model}
\begin{align*}
\dot X &=v\cos(\psi+C_1\delta)\\
\dot Y &=v\sin(\psi+C_1\delta)\\
\dot \psi &= vC_2\delta\\
\dot v &= (C_{m_1}-C_{m_2}v)F_{x_r}-C_{r_2}v^2-C_{r_0}-(v\delta)^2C_2C_1
\end{align*}
\end{block}

[@verschueren2014towards]

## Application: Autonomous Race Car

\begin{block}{Key Equation}
\[\frac{dz}{ds}=\frac{\dot z}{\dot s}\]
\end{block}

\begin{block}{Velocity on the Centerline}
\[\dot s = \frac{1}{1-\kappa_r y_r}(v_x\cos(\psi_e)-v_y\sin(\psi_e))\]
where:
\[\kappa_r=\frac{1}{\rho}\]
\end{block}


## Application: Autonomous Race Car

\begin{block}{Spatial model}
\begin{align*}
\frac{dy_r}{ds}=&\frac{1}{\dot s} (v\sin(\psi)+vC_1\delta\cos(\psi))\\
\frac{d\psi_e}{ds}=&\frac{\dot \psi}{\dot s}-\kappa_r\\
\frac{dv}{ds}=&\frac{\dot v}{\dot s}\\
\frac{dt}{ds}=&\frac{1}{\dot s}
\end{align*}
\end{block}

## Application: Autonomous Race Car

\begin{block}{Spatial model}
- State variables: \[x=\big[y_r,\psi_r,v,t\big]\]
- Control inputs: \[u_c=\big[\delta, F_{x_r}\big]\]
- External input: \[u_e=\big[\kappa_r\big]\]
\end{block}

## Application: Autonomous Race Car

\begin{block}{Optimal Control Problem}
\begin{align*}
\underset{u_c}{\text{minimize}}\ & J(x_0,s_0)=\phi(x(s_f))+\int_{s_0}^{s_f}L(x(\sigma),u_c(\sigma))d\sigma
\end{align*}
\end{block}

\begin{block}{Time Optimal Problem}
\begin{align*}
\phi(x(s_f)) =& t(s_f)\\
L(x(\sigma),u_c(\sigma)) =& 0
\end{align*}
\end{block}

## Application: Autonomous Race Car

\begin{block}{Issues}
\begin{itemize}
\item Trade-off: time-optimality vs tracking and collision avoidance
\item Robustness
\end{itemize}
\end{block}

## References
